{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-78e1c250d64e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Part (c): Read in the data, standardize it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mspam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/spam.data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m test_indicator = pd.read_table('https://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/spam.traintest', sep=' ',\n\u001b[1;32m     12\u001b[0m                                header=None)\n",
      "\u001b[0;32m/Users/tondapu/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tondapu/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     filepath_or_buffer, _, compression = get_filepath_or_buffer(\n\u001b[0;32m--> 392\u001b[0;31m         filepath_or_buffer, encoding, compression)\n\u001b[0m\u001b[1;32m    393\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compression'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tondapu/anaconda/lib/python2.7/site-packages/pandas/io/common.pyc\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_urlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Content-Encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gzip'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tondapu/anaconda/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tondapu/anaconda/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tondapu/anaconda/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 548\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tondapu/anaconda/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tondapu/anaconda/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tondapu/anaconda/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_full_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "\n",
    "# Part (c): Read in the data, standardize it\n",
    "spam = pd.read_table('https://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/spam.data', sep=' ', header=None)\n",
    "test_indicator = pd.read_table('https://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/spam.traintest', sep=' ',\n",
    "                               header=None)\n",
    "\n",
    "x = np.asarray(spam)[:, 0:-1]\n",
    "y = np.asarray(spam)[:, -1]*2 - 1  # Convert to +/- 1\n",
    "test_indicator = np.array(test_indicator).T[0]\n",
    "\n",
    "# Divide the data into train, test sets\n",
    "x_train = x[test_indicator == 0, :]\n",
    "x_test = x[test_indicator == 1, :]\n",
    "y_train = y[test_indicator == 0]\n",
    "y_test = y[test_indicator == 1]\n",
    "\n",
    "# Standardize the data.\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# Keep track of the number of samples and dimension of each sample\n",
    "n_train = len(y_train)\n",
    "n_test = len(y_test)\n",
    "d = np.size(x, 1)\n",
    "\n",
    "# Write a function computegrad that computes and returns rF( ) for any  .\n",
    "def computegrad(beta, lambduh, x=x_train, y=y_train):\n",
    "    yx = y[:, np.newaxis]*x\n",
    "    denom = 1+np.exp(-yx.dot(beta))\n",
    "    grad = 1/len(y)*np.sum(-yx*np.exp(-yx.dot(beta[:, np.newaxis]))/denom[:, np.newaxis], axis=0) + 2*lambduh*beta\n",
    "    return grad\n",
    "\n",
    "# Write a function backtracking that implements the backtracking rule.\n",
    "def objective(beta, lambduh, x=x_train, y=y_train):\n",
    "    return 1/len(y) * np.sum(np.log(1 + np.exp(-y*x.dot(beta)))) + lambduh * np.linalg.norm(beta)**2\n",
    "\n",
    "# Write a function graddescent that implements the gradient descent algorithm with the backtracking rule to tune the step-size. The function graddescent calls computegrad and backtracking as subroutines. The function takes as input the initial point, the initial step-size value, and the maximum number of iterations. The stopping criterion is the maximum number of iterations.\n",
    "def bt_line_search(beta, lambduh, eta=1, alpha=0.5, betaparam=0.8,\n",
    "                   maxiter=100, x=x_train, y=y_train):\n",
    "    grad_beta = computegrad(beta, lambduh, x=x, y=y)\n",
    "    norm_grad_beta = np.linalg.norm(grad_beta)\n",
    "    found_eta = 0\n",
    "    iter = 0\n",
    "    while found_eta == 0 and iter < maxiter:\n",
    "        if objective(beta - eta * grad_beta, lambduh, x=x, y=y) < objective(beta, lambduh, x=x, y=y) \\\n",
    "                - alpha * eta * norm_grad_beta ** 2:\n",
    "            found_eta = 1\n",
    "        elif iter == maxiter:\n",
    "            raise ('Max number of iterations of backtracking'\n",
    "                   ' line search reached')\n",
    "        else:\n",
    "            eta *= betaparam\n",
    "            iter += 1\n",
    "    return eta\n",
    "\n",
    "\n",
    "# Part (f): Gradient descent algorithm\n",
    "def graddescent(beta_init, lambduh, eta_init, maxiter, x=x_train, y=y_train):\n",
    "    beta = beta_init\n",
    "    grad_beta = computegrad(beta, lambduh, x=x, y=y)\n",
    "    beta_vals = beta\n",
    "    iter = 0\n",
    "    while iter < maxiter:\n",
    "        eta = bt_line_search(beta, lambduh, eta=eta_init, x=x, y=y)\n",
    "        beta = beta - eta*grad_beta\n",
    "        # Store all of the places we step to\n",
    "        beta_vals = np.vstack((beta_vals, beta))\n",
    "        grad_beta = computegrad(beta, lambduh, x=x, y=y)\n",
    "        iter += 1\n",
    "        if iter % 100 == 0:\n",
    "            print('Gradient descent iteration', iter)\n",
    "    return beta_vals\n",
    "\n",
    "# Write a function fastgradalgo that implements the fast gradient algorithm described in Algorithm 1. The function fastgradalgo calls computegrad and backtracking as sub- routines. The function takes as input the initial point, the initial step-size value, and the maximum number of iterations. The stopping criterion is the maximum number of iterations.\n",
    "def fastgradalgo(beta_init, theta_init, lambduh, eta_init, maxiter, x=x_train, y=y_train):\n",
    "    beta = beta_init\n",
    "    theta = theta_init\n",
    "    grad_theta = computegrad(theta, lambduh, x=x, y=y)\n",
    "    theta_vals = theta\n",
    "    iter = 0\n",
    "    while iter < maxiter:\n",
    "        eta = bt_line_search(theta, lambduh, eta=eta_init, x=x, y=y)\n",
    "        beta_new = theta - eta*grad_theta\n",
    "        theta = beta_new + iter/(iter+3)*(beta_new-beta)\n",
    "        # Store all of the places we step to\n",
    "        theta_vals = np.vstack((theta_vals, theta))\n",
    "        grad_theta = computegrad(theta, lambduh, x=x, y=y)\n",
    "        beta = beta_new\n",
    "        iter += 1\n",
    "        if iter % 100 == 0:\n",
    "            print('Fast gradient iteration', iter)\n",
    "    return theta_vals\n",
    "\n",
    "# Use the estimate described in the course to initialize the step-size. Set the maximum number of iterations to 1000. Run graddescent and fastgradalgo on the training set of the Spam dataset for   = 0.1. Plot the curve of the objective values F( t) for both algorithms versus the iteration counter t (use different colors). What do you observe?\n",
    "def objective_plot(betas_gd, betas_fg, lambduh, x=x_train, y=y_train, save_file=''):\n",
    "    num_points = np.size(betas_gd, 0)\n",
    "    objs_gd = np.zeros(num_points)\n",
    "    objs_fg = np.zeros(num_points)\n",
    "    for i in range(0, num_points):\n",
    "        objs_gd[i] = objective(betas_gd[i, :], lambduh, x=x, y=y)\n",
    "        objs_fg[i] = objective(betas_fg[i, :], lambduh, x=x, y=y)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(range(1, num_points + 1), objs_gd, label='gradient descent')\n",
    "    ax.plot(range(1, num_points + 1), objs_fg, c='red', label='fast gradient')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Objective value')\n",
    "    plt.title('Objective value vs. iteration when lambda='+str(lambduh))\n",
    "    ax.legend(loc='upper right')\n",
    "    if not save_file:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save_file)\n",
    "\n",
    "\n",
    "lambduh = 0.1\n",
    "beta_init = np.zeros(d)\n",
    "theta_init = np.zeros(d)\n",
    "eta_init = 1/(scipy.linalg.eigh(1/len(y_train)*x_train.T.dot(x_train), eigvals=(d-1, d-1), eigvals_only=True)[0]+lambduh)\n",
    "maxiter = 1000\n",
    "betas_grad = graddescent(beta_init, lambduh, eta_init, maxiter)\n",
    "betas_fastgrad = fastgradalgo(beta_init, theta_init, lambduh, eta_init, maxiter)\n",
    "objective_plot(betas_grad, betas_fastgrad, lambduh, save_file='hw3_q1_part_h_output.png')\n",
    "\n",
    "#Denote by  T the final iterate of your fast gradient algorithm. Compare  T to the  ? found by scikit-learn. Compare the objective value for  T to the one for  ?. What do you observe?\n",
    "lr = sklearn.linear_model.LogisticRegression(penalty='l2', C=1 / (2 * lambduh * n_train), fit_intercept=False,\n",
    "                                             tol=10e-8, max_iter=1000)\n",
    "lr.fit(x_train, y_train)\n",
    "print(lr.coef_)\n",
    "print(betas_fastgrad[-1, :])\n",
    "\n",
    "print(objective(betas_fastgrad[-1, :], lambduh))\n",
    "print(objective(lr.coef_.flatten(), lambduh))\n",
    "\n",
    "\n",
    "# Run cross-validation on the training set of the Spam dataset using scikit-learn to find the optimal value of  . Run graddescent and fastgradalgo to optimize the objective with that value of  . Plot the curve of the objective values F( t) for both algorithms versus the iteration counter t. Plot the misclassification error on the training set for both algorithms versus the iteration counter t. Plot the misclassification error on the test set for both algorithms versus the iteration counter t. What do you observe?\n",
    "def compute_misclassification_error(beta_opt, x, y):\n",
    "    y_pred = 1/(1+np.exp(-x.dot(beta_opt))) > 0.5\n",
    "    y_pred = y_pred*2 - 1  # Convert to +/- 1\n",
    "    return np.mean(y_pred != y)\n",
    "\n",
    "\n",
    "def plot_misclassification_error(betas_grad, betas_fastgrad, x, y, save_file='', title=''):\n",
    "    niter = np.size(betas_grad, 0)\n",
    "    error_grad = np.zeros(niter)\n",
    "    error_fastgrad = np.zeros(niter)\n",
    "    for i in range(niter):\n",
    "        error_grad[i] = compute_misclassification_error(betas_grad[i, :], x, y)\n",
    "        error_fastgrad[i] = compute_misclassification_error(betas_fastgrad[i, :], x, y)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(range(1, niter + 1), error_grad, label='gradient descent')\n",
    "    ax.plot(range(1, niter + 1), error_fastgrad, c='red', label='fast gradient')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Misclassification error')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    ax.legend(loc='upper right')\n",
    "    if not save_file:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save_file)\n",
    "\n",
    "lr_cv = sklearn.linear_model.LogisticRegressionCV(penalty='l2', fit_intercept=False, tol=10e-8, max_iter=1000)\n",
    "lr_cv.fit(x_train, y_train)\n",
    "optimal_lambda = lr_cv.C_[0]\n",
    "print('Optimal lambda=', optimal_lambda)\n",
    "\n",
    "betas_grad = graddescent(beta_init, optimal_lambda, eta_init, maxiter)\n",
    "betas_fastgrad = fastgradalgo(beta_init, theta_init, optimal_lambda, eta_init, maxiter)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
